import torch
import streamlit as st
import io
import imageio
import requests
from PIL import Image
from torchvision import transforms as T
from torchvision.models import densenet121
# from torchvision import io
import torch.nn as nn
import time
from model.predict import predict_1
from yolo_model.yolo8 import detect
import tempfile



# st.set_page_config(layout='wide')

st.title('–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ ‚Ä¢ Computer Vision')


with st.sidebar:
    st.header('–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É')
    page = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É", ["–ì–ª–∞–≤–Ω–∞—è", "–í–µ—Ç—Ä—è–Ω—ã–µ –º–µ–ª—å–Ω–∏—Ü—ã", "–¢–µ–∫—Å—Ç", "–ò—Ç–æ–≥–∏"])

if page == "–ì–ª–∞–≤–Ω–∞—è":
    st.header('–í—ã–ø–æ–ª–Ω–∏–ª–∞ –∫–æ–º–∞–Ω–¥–∞ "YOLO":')
    st.subheader('ü¶Å–ê–ª–µ–∫—Å–µ–π –î.')
    st.subheader('üê±–ï—Ä–ª–∞–Ω')
    st.subheader('üê∞–¢–∞—Ç–∞')
    st.subheader('üêØ–¢–∏–≥—Ä–∞–Ω')

    st.header(" üåü " * 10)

    st.header('–ù–∞—à–∏ –∑–∞–¥–∞—á–∏:')
    st.subheader('*–ó–∞–¥–∞—á–∞ ‚Ññ1*: –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Ç—Ä—è–Ω—ã—Ö –º–µ–ª—å–Ω–∏—Ü')
    st.subheader('*–ó–∞–¥–∞—á–∞ ‚Ññ2*: –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –∑–∞—à—É–º–ª–µ–Ω–∏–π')


elif page == "–í–µ—Ç—Ä—è–Ω—ã–µ –º–µ–ª—å–Ω–∏—Ü—ã":
    st.header("–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è:")
    st.subheader("- –ú–æ–¥–µ–ª—å: *YOLOv8 Nano*")
    st.subheader("- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: *64*")
    st.subheader("- mAP50: *~ 0.83*")

    st.info('–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ .jpg /.jpeg /.png')
    image_url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    start_time = time.time()

    if image_url:

        response = requests.get(image_url)
        image = Image.open(io.BytesIO(response.content))
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_image:
            image.save(temp_image.name)
        st.subheader('–í–∞—à–µ —Ñ–æ—Ç–æ –¥–æ –¥–µ—Ç–µ–∫—Ü–∏–∏:')
        st.image(image, caption='Original Image', use_column_width=True)

        show_result_button1 = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", key="result_button_1")

        if show_result_button1:
            st.success("–í–∞—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–æ—Ç–æ–≤!")
            st.subheader('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:')
            detection_result = detect(temp_image.name)
    # –í—ã–≤–µ–¥–µ–Ω–∏–µ –≤—Ç–æ—Ä–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–∞–º–∫–∞–º–∏
            st.image(detection_result, caption='Image with Detection Result', use_column_width=True)
            st.subheader(f'–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {round((time.time() - start_time), 2)} —Å–µ–∫.')
            st.header('üéà' * 10)

    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"])
    start_time_file = time.time()
    if uploaded_file is not None:
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_image:
            uploaded_image = Image.open(uploaded_file)
            uploaded_image.save(temp_image.name)
        st.subheader('–í–∞—à–µ —Ñ–æ—Ç–æ –¥–æ –¥–µ—Ç–µ–∫—Ü–∏–∏:')
        st.image(uploaded_image, caption='Original Image', use_column_width=True)

        show_result_button2 = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", key="result_button_2")
        if show_result_button2:
            st.success("–í–∞—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–æ—Ç–æ–≤!")

            st.subheader("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:")
            prediction_result_file = detect(temp_image.name)
            st.image(prediction_result_file, caption='Image with Detection Result', use_column_width=True)
            st.subheader(f'–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {round((time.time() - start_time_file), 2)} —Å–µ–∫.')
            st.header('üéà' * 10)


elif page == "–¢–µ–∫—Å—Ç":
    st.header("–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è:")

    st.subheader("- –ú–æ–¥–µ–ª—å: *ConvAutoencoder()*")
    st.subheader("- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: *100*")

    st.info('–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ .jpg /.jpeg /.png')
    image_url2 = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    start_time2 = time.time()

    if image_url2:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ
        response2 = requests.get(image_url2)
        image2 = Image.open(io.BytesIO(response2.content))
        st.subheader('–í–∞—à–µ —Ñ–æ—Ç–æ –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏:')
        st.image(image2)
        prediction_result = predict_1(image2)

        show_result_button3 = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", key="result_button_3")
        if show_result_button3:
            st.success("–í–∞—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–æ—Ç–æ–≤!")

            st.subheader("–í–∞—à–µ —Ñ–æ—Ç–æ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            st.image(prediction_result, channels='GRAY')
            st.subheader(f'–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {round((time.time() - start_time2), 2)} —Å–µ–∫.')
            st.header('üéà' * 10)

    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"])
    start_time_file = time.time()

    if uploaded_file is not None:
        image_file = Image.open(uploaded_file)
        st.subheader('–í–∞—à–µ —Ñ–æ—Ç–æ –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏:')
        st.image(image_file)
        prediction_result_file = predict_1(image_file)

        show_result_button4 = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", key="result_button_4")
        if show_result_button4:
            st.success("–í–∞—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–æ—Ç–æ–≤!")
            st.subheader("–í–∞—à–µ —Ñ–æ—Ç–æ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            st.image(prediction_result_file, channels='GRAY')
            st.subheader(f'–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {round((time.time() - start_time_file), 2)} —Å–µ–∫.')
            st.header('üéà' * 10)



elif page == "–ò—Ç–æ–≥–∏":
    st.header('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≤–æ–¥—ã')
    st.subheader('*–ó–∞–¥–∞—á–∞ ‚Ññ1*: –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Ç—Ä—è–Ω—ã—Ö –º–µ–ª—å–Ω–∏—Ü')

    st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∏–∑ Clear ML")
    image_1 = Image.open("pictures/P_curve.png")
    image_2 = Image.open("pictures/PR_curve.png")
    image_3 = Image.open("pictures/R_curve.png")
    image_4 = Image.open("pictures/F1_curve.png")

# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
    st.image([image_1, image_2, image_3, image_4], caption=['Image 1 - P_curve', 'Image 2 - PR_curve', 'Image 3 - R_curve', 'Image 4 - F1_curve'], width=300)

    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –∏–∑ Clear ML")
    image_5 = imageio.imread('pictures/plots.jpg')[:, :, :]
    st.image(image_5)
    st.subheader("–û–±—É—á–µ–Ω–∏–µ")
    image_6 = imageio.imread('pictures/train.png')[:, :, :]
    st.image(image_6)

    st.subheader("Confusion matrix")

    image_7 = imageio.imread("pictures/confusion_matrix.png")[:, :, :]
    st.image(image_7)

    st.subheader("Confusion matrix normolized")
    
    image_8 = imageio.imread('pictures/confusion_matrix_normalized.png')[:, :, :]
    st.image(image_8)

    st.subheader("–ï—â–µ –º—ã –ø—Ä–æ–±–æ–≤–∞–ª–∏ *YOLOv8 Medium* –Ω–∞ 30 —ç–ø–æ—Ö–∞—Ö:")
    st.markdown('YOLOv8 Medium')

    image_9 = imageio.imread('pictures/pt1-3.png')[:, :, :]
    st.image(image_9)

    st.markdown('YOLOv8 Nano')
    
    image_10 = imageio.imread('pictures/pt1-2.png')[:, :, :]
    st.image(image_10)

    st.markdown('YOLOv8 Medium')

    image_11 = imageio.imread('pictures/pt2-3.png')[:, :, :]
    st.image(image_11)

    st.markdown('YOLOv8 Nano')
    
    image_12 = imageio.imread('pictures/pt2-2.png')[:, :, :]
    st.image(image_12)


    st.subheader('*–ó–∞–¥–∞—á–∞ ‚Ññ2*: –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –∑–∞—à—É–º–ª–µ–Ω–∏–π')
    st.subheader("–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å:")
    st.subheader("*criterion = nn.L1Loss()*")
    st.subheader('*optimizer = torch.optim.SGD(model.parameters(), lr=0.005)")*')
    image_9 = imageio.imread('pictures/model.png')[:, :, :]
    st.image(image_9)
